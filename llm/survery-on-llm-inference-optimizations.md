# Survery on LLM inference optimizations

